# Pytorch Advanced

## 1. VGG

### 1.1 학습된 VGG 모델을 사용하는 방법
- VGG-16 모델은 2014년 ILSVRC에서 2위를 차지
- 구성이 간단하여 다양한 딥러닝 응용  기술의 기반 네트워크로 사용됨
- 층 수에 FC layer, Convolution layer는 포함되나 활성화함수, 풀링층, 드롭아웃 등은 포함되지 않음
- 파이토치와 필로는 이미지 구성 차원 순서가 다름
  - 파이토치: (채널, 높이, 너비)
  - 필로: (높이, 너비, 채널)
  - `img_transformed = img_transformed.numpy().transpose((1, 2, 0))`
- `__call__()`은 파이썬의 일반 메서드. 구체적 함수를 지정하지 않고 호출하면 실행되는 함수
- torch.detach(): 출력값을 네트워크에서 분리
- 파이토치 네트워크에 이미지를 입력할 때 데이터는 미니배치 형태가 되어야 함
  - `unsqueeze_(0)` 메소드로 입력 데이터에 미니배치 차원 추가

### 1.2 파이토치를 활용한 딥러닝 구현 흐름
- 파이토치 딥러닝 구현 흐름
   1. 전처리, 후처리, 네트워크 모델의 입출력 확인
   2. 데이터셋 작성
       - 입력 데이터와 라벨 등을 쌍으로 갖는 클래스
       - 전처리 클래스의 인스턴스를 할당하여, 파일을 읽을 때 자동으로 전처리 적용
   3. 데이터 로더 작성
       - 데이터를 어떻게 가져올지 설정하는 클래스
       - Dataset에서 미니배치를 쉽게 가져오도록 설정         
   4. 네트워크 모델 작성
   5. 순전파 정의
   6. 손실함수 정의
   7. 최적화 기법 설정
   8. 학습/검증 실시
   9. 테스트 데이터로 추론


### 1-3. 전이학습 구현
- 데이터셋에서 augmentation도 함
  - 에폭마다 다르게 적용
  - ex) resized crop, horizontal flip ...

- glob을 이용하여 하위 디렉토리 파일 경로를 불러올 수 있음

- Dataset 작성 시, 기존 Pytorch의 Dataset 상속
  - 이때 `__len__`과 `__getitem__` 메서드 구현해야 함

- 메모리가 부족한 경우 batch_size를 작게 수행해야 함
- DataLoader 사용 시, train 시에는 shuffle=True, validation 시에는 shuffle=False

- 전이학습으로 학습하고 변화시킬 파라미터를 설정해야 함
  - ex. `update_param_names = ["classifier.6.weight", "classifier.6.bias"]`
- 학습시킬 파라미터 외에는 경사를 계산하지 않고 변하지 않도록 설정 -> 반드시 이래야 할까?
  - `param.requires_grad = False`

- 학습하지 않을 시 검증 선능을 확인하기 위해 epoch=0의 훈련 생략
- 학습 시 손실은 미니배치 크기의 평균 값으로 나옴. 따라서 미니배치 크기를 곱해 미니배치의 총 손실을 구함
  - `epoch_loss += loss.item() * inputs.size(0)`


- AWS AMI에 딥러닝을 위한 'Deep Learning AMI'가 있음
  - 파이토치, 텐서플로, 케라스. CUDA 등 패키지가 아나콘다와 함께 이미 설치돼있음
- 주피터 노트북은 기본적으로 8888번 포트에서 시작됨
  - 로컬환경과 클라우드 환경이 겹치지 않게 하려면 포트를 다르게 설정하면 좋음(ex. 9999포트)


- 파인튜닝과 전이학습은 다른 것
  - 전이학습은 출력층만 재학습
  - 파인튜닝은 모든 층의 파라미터 재학습
    - 일반적으로 입력층에 가까운 부분의 파라미터는 학습률 작게
    - 출력층에 가까운 부분의 파라미터는 학습률 크게
- GPU 상에 저장한 파일을 CPU에 로드할 때는 map_location을 사용해야 함

## 2. SSD
- Single Shot MultiBox Detector; 물체감지 모델
- 물체 감지는 딥러닝 응용 기술 중에서도 특히 복잡
- 물체 감지: 한 장의 사진에 포함된 여러 물체에 대해 영역과 이름을 확인하는 작업
- 바운딩박스(BBox): 물체의 위치를 나타내는 테두리
- 물체감지 모델 입출력
  - 입력: 이미지
  - 출력: 바운딩 박스의 위치, 크기. 바운딩 박스의 라벨. 검색 신뢰도
- 바운딩 박스 표현법
  1. (xmin, ymin), (xmax, ymax)
  2. (cx, cy), w, h
- 전체 라벨 수 = 감지하려는 물체 수 + 1(배경 클래스)
- SSD는 300 * 300 / 512 * 512 2가지 패턴 존재
- SSD는 바운딩 박스의 정보를 바로 출력하는 것이 아님
  - 디폴트박스(DBox)를 준비해두고 어떻게 변형시키면 바운딩 박스가 되는지에 대한 정보를 출력
    - DBox를 변형시키는 정보를 오프셋 정보라고 함
- 물체감지 흐름 6단계(SSD300 기준)
  1. 이미지 리사이즈(300 * 300)
  2. 디폴트 박스 준비(8,732개)
  3. SSD 네트워크에 화상 입력(출력 = 8,732 * 클래스 수 * 오프셋정보 4개)
  4. 신뢰도 높은 디폴트 박스 추출
  5. 오프셋 정보로 수정 및 중복 제거
  6. 일정 신뢰도 이상을 최종 출력으로 선정

- 파이토치 기본 딥러닝 흐름
  - 